{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:25.243996Z",
     "start_time": "2019-11-18T03:59:22.601493Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $n=1$, we can fit a degree-$m$ polynomial by choosing $f_{j}(x)=x^{j-1}$ and $M=m+1$. \n",
    "In this case, it follows that $A_{i,j}=x_{i}^{j-1}$\n",
    "and the matrix $A$ is called a Vandermonde matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to create Vandermonde matrix **(5pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:25.274808Z",
     "start_time": "2019-11-18T03:59:25.248060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.,   1.,   1.],\n",
       "       [  1.,   2.,   4.,   8.],\n",
       "       [  1.,   3.,   9.,  27.],\n",
       "       [  1.,   4.,  16.,  64.],\n",
       "       [  1.,   5.,  25., 125.],\n",
       "       [  1.,   6.,  36., 216.],\n",
       "       [  1.,   7.,  49., 343.],\n",
       "       [  1.,   8.,  64., 512.],\n",
       "       [  1.,   9.,  81., 729.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_vandermonde(x, m):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        x {numpy.ndarray} -- 1d-array of (x_1, x_2, ..., x_n)\n",
    "        m {int} -- a non-negative integer, degree of polynomial fit\n",
    "    Returns:\n",
    "        A {numpy.ndarray} -- an n x (m+1) matrix where A_{ij} = x_i^{j-1}\n",
    "    \"\"\"\n",
    "    A = np.zeros((x.shape[0], m+1))\n",
    "    for i in range(0,m+1):\n",
    "        A[:,i] = np.power(x,i)\n",
    "    return A\n",
    "\n",
    "x = np.arange(1, 10)\n",
    "create_vandermonde(x, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T08:20:31.914140Z",
     "start_time": "2018-11-11T08:20:31.910401Z"
    }
   },
   "source": [
    "Write a function to solve least-square problem **(5pt)**\n",
    "\n",
    "Implementation hint: check `numpy.linalg.lstsq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:25.291299Z",
     "start_time": "2019-11-18T03:59:25.281475Z"
    }
   },
   "outputs": [],
   "source": [
    "def solve_linear_LS(A, y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        A {numpy.ndarray} -- an m x n matrix\n",
    "        y {numpy.ndarray} -- a length-n vector\n",
    "    Returns:\n",
    "        z_hat {numpy.ndarray} -- length-m vector, the optimal solution for the given linear least-square problem\n",
    "    \"\"\"\n",
    "    z_hat = np.linalg.lstsq(A,y, rcond=-1)\n",
    "    return z_hat[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T23:36:44.151406Z",
     "start_time": "2018-11-10T23:36:44.147872Z"
    }
   },
   "source": [
    "Using the setup in the previous example, try fitting the points $(1,2),(2,3),(3,5),(4,7),(5,11),(6,13)$\n",
    "to a degree-2 polynomial.\n",
    "\n",
    "Compute the minimum squared error. **(5pt)**\n",
    "\n",
    "Plot this polynomial (for $x\\in[0,7]$) along with the data points to see the quality of fit. **(5pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:25.770064Z",
     "start_time": "2019-11-18T03:59:25.296218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best polynomial fit is 0.3214 x^2 + 0.2071 x^1 + 1.4000\n",
      "minimum squared error is 0.0810\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5, 6])\n",
    "y = np.array([2, 3, 5, 7, 11, 14])\n",
    "m = 2\n",
    "\n",
    "# Create Vandermonde matrix A\n",
    "A = create_vandermonde(x,m)\n",
    "\n",
    "# Solve least square problem to minimize || y - A z ||^2\n",
    "z_hat = solve_linear_LS(A,y)\n",
    "\n",
    "# Compute the minimum square error\n",
    "mse = sum(np.power((y-np.sum((A*z_hat),1)),2))/len(y)\n",
    "\n",
    "# Generate plot points for the fitted polynomial\n",
    "xx = x\n",
    "yy = np.sum(A*z_hat, 1)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(x, y, color='red', label='data points')\n",
    "plt.plot(xx, yy, label='polynomial fit')\n",
    "plt.legend()\n",
    "\n",
    "poly_expr = ' + '.join(['{0:.4f} x^{1}'.format(v, i) for i, v in enumerate(z_hat)][::-1])[:-4]\n",
    "print('best polynomial fit is {0}'.format(poly_expr))\n",
    "print('minimum squared error is {0:.4f}'.format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read `mnist_train.csv`, create a dataframe with two columns, column `feature` contains all $x$ and column `label` contains all $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:45.319748Z",
     "start_time": "2019-11-18T03:59:45.315324Z"
    }
   },
   "outputs": [],
   "source": [
    "# read mnist csv file to a dataframe\n",
    "df = pd.read_csv('mnist_train.csv')\n",
    "\n",
    "# append feature column by merging all pixel columns\n",
    "df['feature'] = df.apply(lambda row: row.values[1:], axis=1)\n",
    "\n",
    "# only keep feature and label column\n",
    "df = df[['feature', 'label']]\n",
    "\n",
    "# display first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the first 30 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:26.257690Z",
     "start_time": "2019-11-18T03:59:22.627Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 2.5))\n",
    "for i, row in df.iloc[:30].iterrows():\n",
    "    x, y = row['feature'], row['label']\n",
    "    plt.subplot(2, 15, i + 1)\n",
    "    plt.imshow(x.reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the all samples labeled with digit $n$ and randomly separate the samples into equal-sized training and testing groups. **(10pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:26.269561Z",
     "start_time": "2019-11-18T03:59:22.631Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_and_split(df, d, test_size=0.5):\n",
    "    \"\"\"\n",
    "    extract the samples with given lables and randomly separate the samples into equal-sized training and testing groups, extend each vector to length 785 by appending a −1\n",
    "    Arguments:\n",
    "        df {dataframe} -- the dataframe of MNIST dataset\n",
    "        d {int} -- digit needs to be extracted, can be 0, 1, ..., 9\n",
    "        test_size {float} -- the fraction of testing set, default value is 0.5\n",
    "    Returns:\n",
    "        X_tr {numpy.ndarray} -- training set features, a matrix with 785 columns\n",
    "                                each row corresponds the feature of a sample\n",
    "        y_tr {numpy.ndarray} -- training set labels, 1d-array\n",
    "                                each element corresponds the label of a sample\n",
    "        X_te {numpy.ndarray} -- testing set features, a matrix with 785 columns \n",
    "                                each row corresponds the feature of a sample\n",
    "        y_te {numpy.ndarray} -- testing set labels, 1d-array\n",
    "                                each element corresponds the label of a sample\n",
    "    \"\"\"\n",
    "    digit = df[df.label == d]\n",
    "    X = digit.values[:,0]\n",
    "    y = digit.values[:,1]\n",
    "    inds0 = np.random.choice(X.shape[0],size=X.shape[0])\n",
    "    X = X[inds0]\n",
    "    y = y[inds0]\n",
    "    X_tr = np.stack((X[0:int(test_size*X.shape[0])]), axis=0)\n",
    "    X_te = np.stack((X[int(test_size*X.shape[0]):X.shape[0]]), axis=0)\n",
    "    y_tr = np.array(y[0:int(test_size*y.shape[0])])\n",
    "    y_te = np.array(y[int(test_size*y.shape[0]):y.shape[0]])\n",
    "    return X_tr, X_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful preprocess function before you draw histogram.\n",
    "Sometimes your histogram becomes ugly because of the existence of outlier points.\n",
    "The function below drops the unwanted outlier points, please call this function before you pass your result to draw a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:26.286086Z",
     "start_time": "2019-11-18T03:59:22.635Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_outlier(x, thresh=3.5):\n",
    "    \"\"\"\n",
    "    returns points that are not outliers to make histogram prettier\n",
    "    reference: https://stackoverflow.com/questions/11882393/matplotlib-disregard-outliers-when-plotting/11886564\n",
    "    Arguments:\n",
    "        x {numpy.ndarray} -- 1d-array, points to be filtered\n",
    "        thresh {float} -- the modified z-score to use as a threshold. Observations with\n",
    "                          a modified z-score (based on the median absolute deviation) greater\n",
    "                          than this value will be classified as outliers.\n",
    "    Returns:\n",
    "        x_filtered {numpy.ndarray} -- 1d-array, filtered points after dropping outlier\n",
    "    \"\"\"\n",
    "    if len(x.shape) == 1: x = x[:,None]\n",
    "    median = np.median(x, axis=0)\n",
    "    diff = np.sqrt(((x - median)**2).sum(axis=-1))\n",
    "    modified_z_score = 0.6745 * diff / np.median(diff)\n",
    "    x_filtered = x[modified_z_score <= thresh]\n",
    "    return x_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairwise experiment for applying least-square to classify digit $a$ and digit $b$. \n",
    "\n",
    "Follow the given steps in the template and implement the function for pairwise experiment **(25pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:26.305953Z",
     "start_time": "2019-11-18T03:59:22.640Z"
    }
   },
   "outputs": [],
   "source": [
    "def mnist_pairwise_LS(df, a, b, test_size=0.5, verbose=False):\n",
    "    \"\"\"\n",
    "    Pairwise experiment for applying least-square to classify digit a and digit b\n",
    "    Arguments:\n",
    "        df {dataframe} -- the dataframe of MNIST dataset\n",
    "        a, b {int} -- digits to be classified\n",
    "        test_size {float} -- the fraction of testing set, default value is 0.5\n",
    "        verbose {bool} -- whether to print and plot results\n",
    "    Returns:\n",
    "        res {numpy.ndarray} -- numpy.array([traing error, testing error])\n",
    "    \"\"\"\n",
    "    # Find all samples labeled with digit a and split into train/test sets\n",
    "    Xa_tr, Xa_te, ya_tr, ya_te = extract_and_split(df, a, test_size)\n",
    "    # Find all samples labeled with digit b and split into train/test sets\n",
    "    Xb_tr, Xb_te, yb_tr, yb_te = extract_and_split(df, b, test_size)\n",
    "    ya_tr = [-1 for i in ya_tr]\n",
    "    yb_tr = [1 for i in yb_tr]\n",
    "    ya_te = [-1 for i in ya_te]\n",
    "    yb_te = [1 for i in yb_te]\n",
    "    \n",
    "    # Construct the full training set\n",
    "    X_tr = np.concatenate((Xa_tr, Xb_tr), axis=0)\n",
    "    X_tr = np.append(X_tr, -1*np.ones((X_tr.shape[0],1)), 1)\n",
    "    y_tr = np.concatenate((ya_tr, yb_tr), axis=0)\n",
    "    # Construct the full testing set\n",
    "    X_te = np.concatenate((Xa_te, Xb_te), axis=0)\n",
    "    X_te = np.append(X_te, -1*np.ones((X_te.shape[0],1)), 1)\n",
    "    y_te = np.concatenate((ya_te, yb_te), axis=0)\n",
    "    \n",
    "    # Run least-square on training set\n",
    "    z_hat = solve_linear_LS(X_tr.astype(float),y_tr.astype(float))\n",
    "\n",
    "    # Compute estimation and misclassification on training set\n",
    "    mask = list(map(lambda i: 1 if i >= 0 else -1, (X_tr @ z_hat)))\n",
    "    y_hat_tr = np.array(mask, dtype = int).flatten()\n",
    "    err_tr = np.sum(np.array([y_hat_tr != y_tr]))/len(y_tr)\n",
    "\n",
    "    # Compute estimation and misclassification on training set\n",
    "    y_t = X_te @ z_hat\n",
    "    y_hat_te= list(map(lambda i: -1 if i < 0 else 1, y_t))\n",
    "    y_hat_te = np.array(y_hat_te, dtype=int).flatten()\n",
    "    err_te = np.sum(np.array([y_hat_te != y_te]))/len(y_te)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Pairwise experiment, mapping {0} to -1, mapping {1} to 1'.format(a, b))\n",
    "        print('training error = {0:.2f}%, testing error = {1:.2f}%'.format(100 * err_tr, 100 * err_te))\n",
    "        # Compute confusion matrix\n",
    "        cm = confusion_matrix(y_te.astype(int), y_hat_te.astype(int))\n",
    "        print('Confusion matrix:\\n {0}'.format(cm))\n",
    "        # Compute the histogram of the function output separately for each class \n",
    "        # Then plot the two histograms together\n",
    "        ya_te_hat, yb_te_hat = np.split(y_t, [len(ya_te)])\n",
    "        output = [remove_outlier(ya_te_hat), remove_outlier(yb_te_hat)]\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.hist(output, bins=50)\n",
    "    \n",
    "    res = np.array([err_tr, err_te])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairwise experiment for applying least-square to classify digit $0$ and digit $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:26.325163Z",
     "start_time": "2019-11-18T03:59:22.644Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_pairwise_LS(df, 0, 1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above problem for all pairs of digits. For each pair of digits, report the classification error rates for the training and testing sets. The error rates can be formatted nicely into a triangular matrix. **(15pt)**\n",
    "\n",
    "For example, you can put all testing error in the lower triangle and all training error in the upper triangle.\n",
    "You may run the classification several times to get an average error rate over different sample split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:26.332882Z",
     "start_time": "2019-11-18T03:59:22.650Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "num_trial, err_matrix = 1, np.zeros((10, 10))\n",
    "\n",
    "# Fill the err_matrix, for all a < b\n",
    "# err_matrix[a, b] = training error between digits a and b\n",
    "# err_matrix[b, a] = testing error between digits a and b\n",
    "for i in range (10):\n",
    "    for j in range(i):\n",
    "        err = mnist_pairwise_LS(df,j,i)\n",
    "        err_matrix[j,i] = err[0]\n",
    "        err_matrix[i,j] = err[1]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(err_matrix)\n",
    "plt.title('upper triangle: training error; lower triangle: testing error');\n",
    "print(np.round(err_matrix*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, what about a multi-class classifier for MNIST digits? \n",
    "For multi-class linear classification with d classes, one standard approach is to learn a linear mapping $f \\colon \\mathbb{R}^n \\to \\mathbb{R}^d $ where the “$y$”-value for the $i$-th class is chosen to be the standard basis vector $ \\underline{e}_i \\in \\mathbb{R}^d $. \n",
    "This is sometimes called one-hot encoding. \n",
    "Using the same $A$ matrix as before and a matrix $Y$, defined by $Y_{i,j}$ if observation $i$ in class $j$ and $Y_{i,j} = 0$ otherwise, we can solve for the coefficient matrix $Z \\in \\mathbb{R}^d$ coefficients .\n",
    "Then, the classifier maps a vector $\\underline{x}$ to class $i$ if the $i$-th element of $Z^T \\underline{x}$ is the largest element in the vector. \n",
    "\n",
    "Follow the given steps in the template and implement the function for multi-class classification experiment **(30pt)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:26.337310Z",
     "start_time": "2019-11-18T03:59:22.655Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_one_hot(targets, nb_classes):\n",
    "        res = np.eye(nb_classes)[np.array(targets, dtype = int).reshape(-1)]\n",
    "        return res.reshape(list(targets.shape)+[nb_classes])\n",
    "        #return np.squeeze(np.eye(nb_classes)[targets.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:26.350337Z",
     "start_time": "2019-11-18T03:59:22.659Z"
    }
   },
   "outputs": [],
   "source": [
    "def mnist_onehot_LS(df, test_size=0.5):\n",
    "    \"\"\"\n",
    "    Experiment for applying least-square to classify all digits using one-hot encoding\n",
    "    Arguments:\n",
    "        df {dataframe} -- the dataframe of MNIST dataset\n",
    "        test_size {float} -- the fraction of testing set, default value is 0.5\n",
    "    Returns:\n",
    "        res {numpy.ndarray} -- numpy.array([traing error, testing error])\n",
    "    \"\"\"\n",
    "    inds0 = np.arange(len(df))\n",
    "    np.random.shuffle(inds0)\n",
    "    df = df.iloc[inds0]\n",
    "    \n",
    "    # Split into training/testing set\n",
    "    tr = df.iloc[0:int(test_size*len(df))]\n",
    "    te = df.iloc[int(test_size*len(df)):len(df)]\n",
    "   \n",
    "    # Construct the training set\n",
    "    X_tr = np.stack(tr.values[:,0], axis=0)\n",
    "    X_tr = np.append(X_tr, -1*np.ones((X_tr.shape[0],1)), 1)\n",
    "    y_tr = np.array(tr.values[:,1])\n",
    "    \n",
    "    # Construct the testing set\n",
    "    X_te = np.stack(te.values[:,0], axis=0)\n",
    "    X_te = np.append(X_te, -1*np.ones((X_te.shape[0],1)), 1)\n",
    "    y_te = np.array(te.values[:,1])\n",
    "    \n",
    "    # Apply one-hot encoding to training labels\n",
    "    Y = get_one_hot(y_tr, 10)\n",
    "    \n",
    "    # Run least-square on training set\n",
    "    Z = solve_linear_LS(X_tr, Y)\n",
    "    \n",
    "    # Compute estimation and misclassification on training set\n",
    "    y_hat_tr = X_tr @ Z\n",
    "    err_tr = np.sum(np.array([np.argmax(y_hat_tr, axis=1) != y_tr]))/len(y_tr)\n",
    "    \n",
    "    # Compute estimation and misclassification on training set\n",
    "    y_hat_te = X_te @ Z\n",
    "    err_te = np.sum(np.array([np.argmax(y_hat_te, axis=1) != y_te]))/len(y_te)\n",
    "    \n",
    "    print('training error = {0:.2f}%, testing error = {1:.2f}%'.format(100 * err_tr, 100 * err_te))\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_te.astype(int), np.argmax(y_hat_te, axis=1).astype(int))\n",
    "    print('Confusion matrix:\\n {0}'.format(cm))\n",
    "    return np.array([err_tr, err_te])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T03:59:26.355062Z",
     "start_time": "2019-11-18T03:59:22.663Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_onehot_LS(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "309px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
